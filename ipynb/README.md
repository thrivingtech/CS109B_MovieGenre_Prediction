All jupyter notebooks are written using Python except unless mentioned:

1. Milestone1.ipynb: This notebook explores API used to extract TBDb data and IMDB data

2. Milestone2.ipynb: This notebook explores around the idea of stitching data grom TMDb 
					 and IMDB

3. Milestone3_01_DataPreparation.ipynb: This notebook idea of stitching IMDB and TMDB 
										data that is to be used for traditional models, 
										generated brightness level from poster images, 
										bag of words from IMDB's keyword field,
										Class generation of custom genre
				input: IMDB and TMDB APIs
				output: movies_allfeaturesfinal.csv

4. Milestone3_02_Transform_Metadata.ipynb: This is written in R. 
										   This notebook takes the dataset of all features
										   and extracts only needed features with 
										   approprieate filters
				input: movies_allfeaturesfinal.csv (file included in dataset)
				output: unfiltered_train_data.csv
				        unfiltered_test_data.csv
						filtered_train_data.csv (unused)
						filtered_test_data.csv (unused)

5. Milestone3_03_TraditionalModels.ipynb: This is written in R.
										  This notebook takes in unfiltered data from 
										  above step, and runs multiple traditional 
										  machine learning algorithms and finally compares
										  results generated by each of the models
				input: unfiltered_train_data.csv
				       unfiltered_test_data.csv

6. Milestone4_01_ExtratMorePosters.ipynb: We have extracted close to 20,000 rows from 
										  TMDB to help collect more data for deep learning
				input: IMDB and TMDB APIs
				output: movie_df_final.csv

7. Milestone4_02_TMDB_Poster_Download.ipynb: This notebook takes close to 20,000 movies
											 and extracts posters for all of the movies
				input: movie_df_final.csv
				output: 18566 posters manually moved to 'raw_posters' folder 
						(1.5 GB, not included)

8. Milestone4_03_GenerateCustomClasses.ipynb: This notebook takes genre as multi lable,
											   and translates it to custom classes
				input: y_raw.csv
				output y.csv
						
9. Milestone4_04_DataPreparation.ipynb: This notebook takes raw posters and filters out
										 unwanted posters and converts images to numpy 
										 arrays.  Then the arrays are split to Train and 
										 Test datasets to be distributed between teams.
										 This code also uses the file 'y' generated in 
										 step. The input to above script comes from this 
										 script and the output of above script is used back
										 here.  In order to retain the execution status of
										 notebooks we have not integrated the code, but
										 ideally we would like to integrate the code
				input: raw_posters, movie_df_final.csv, y.csv
				output: y_raw.csv,  
						'posters' folder with all required images
						movie_data.npz: images and genre split to train and test saved as 
										numpy arrays. 5GB size, so included sample file
						movie_data_compressed.npz: images and genre split to train and test
										saved as compressed numpy arrays. 1.5 5GB size, so
										included sample file only

10. Milestone4_05_PreTrainedModel.ipynb: This notebook used one of the pretrained model,
										 InceptionV3, and is fine tuned to get better accuracy
				input: movie_data_compressed.npz
				output: Model Results
					
11. Milestone4_06_ModelFromScratch.ipynb: This notebook implement a CNN model implemented from
										  scratch and is fine tuned to get better accuracy
				input: movie_data_compressed.npz
				output: Model Results

12. Milestone5_01_ImageAug_DataPrep.ipynb: This notebook divides posters to train, test and 
										   validation dolders and slo further divided the 
										   images to folders of the classes
				input: y.csv, 'posters' folder
				output: data/train/0...7; data/test/0...7; data/validation/0...7
				
13. Milestone5_02_ScratchModel_ImgAug.ipynb: This notebook implements same exact scatch 
											 model like above but uses Image Generators
											 augmenting the images.
				output: data/train/0...7; data/test/0...7; data/validation/0...7
				output: Model Results
